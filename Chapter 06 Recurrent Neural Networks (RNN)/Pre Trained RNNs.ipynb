{"cells":[{"cell_type":"markdown","id":"ed02574b-53ff-4cbd-9264-8c6932a928bd","metadata":{"id":"ed02574b-53ff-4cbd-9264-8c6932a928bd"},"source":["# **Recurrent Neural Networks**\n"]},{"cell_type":"markdown","id":"0545db63-0ae3-44c5-8bcc-cc843ce099fe","metadata":{"id":"0545db63-0ae3-44c5-8bcc-cc843ce099fe"},"source":["\n","A recurrent neural network (RNN) is a type of artificial neural network which uses sequential data or time series data as input. Its typically used for ordinal or temporal problems like language translation, speech recognition, and time series forecasting. \n","\n","In this lab, we will understand the fundamental building blocks of an RNN. We will train a simple binary text classifier on top of an existing pre-trained module that embeds sentences."]},{"cell_type":"markdown","id":"6ffa8ef1-5e18-40ee-99ce-ab622b8620fa","metadata":{"id":"6ffa8ef1-5e18-40ee-99ce-ab622b8620fa"},"source":["## Objectives\n","\n","After completing this lab you will be able to:\n","\n"," - Describe the fundamental building blocks of RNNs.\n"," - Implement pre-trained RNNs to solve time-series prediction, and forecasting, and text classification tasks\n"]},{"cell_type":"markdown","id":"dbfc0cd0-37a4-493b-9b82-9dcd3903de65","metadata":{"id":"dbfc0cd0-37a4-493b-9b82-9dcd3903de65"},"source":["----\n"]},{"cell_type":"code","execution_count":null,"id":"7ed95664-21fc-4793-a49d-b3bb4d4bc237","metadata":{"id":"7ed95664-21fc-4793-a49d-b3bb4d4bc237"},"outputs":[],"source":["%%capture\n","\n","!pip install tensorflow_hub\n","!pip install tensorflow --upgrade\n","!mamba install -qy tqdm"]},{"cell_type":"markdown","id":"b711e10d-ec44-48cb-b35f-d0a63bc4ade8","metadata":{"id":"b711e10d-ec44-48cb-b35f-d0a63bc4ade8"},"source":["### Importing Required Libraries\n"]},{"cell_type":"code","execution_count":null,"id":"5eaee927-895f-4fb1-900d-30fdc8aa7391","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eaee927-895f-4fb1-900d-30fdc8aa7391","executionInfo":{"status":"ok","timestamp":1685292365677,"user_tz":-330,"elapsed":6990,"user":{"displayName":"S NIKHIL RAO","userId":"17719059677933628828"}},"outputId":"35c418a1-7cab-4fe7-ee2b-b10361087485"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.12.0\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import math\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","import tensorflow as tf\n","print(tf. __version__)\n","import skillsnetwork\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.losses import mean_squared_error\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Masking,LSTM, GRU, Conv1D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Embedding, SimpleRNN\n","from tensorflow.keras.datasets import reuters\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n","import tensorflow_hub as hub\n","\n","\n","# You can also use this section to suppress warnings generated by your code:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","warnings.filterwarnings('ignore')\n","\n","sns.set_context('notebook')\n","sns.set_style('white')\n","np.random.seed(2024)"]},{"cell_type":"markdown","id":"64c057cc-32a4-4c85-8462-3e391dcd86ce","metadata":{"id":"64c057cc-32a4-4c85-8462-3e391dcd86ce"},"source":["## Helper Functions\n"]},{"cell_type":"code","execution_count":null,"id":"60a05cb5-eafb-4096-8778-02123df6504b","metadata":{"id":"60a05cb5-eafb-4096-8778-02123df6504b"},"outputs":[],"source":["# function to compute the accuracy, precision, recall and F1 score of a model's predictions.\n","def calculate_results(y_true, y_pred):\n","    model_accuracy = accuracy_score(y_true, y_pred)\n","    model_precision, model_recall, model_f1,_ = precision_recall_fscore_support(y_true, y_pred,average=\"weighted\")\n","    model_results = {\"accuracy\":model_accuracy,\n","                     \"precision\":model_precision,\n","                     \"recall\" :model_recall,\n","                     \"f1\":model_f1}\n","    return model_results"]},{"cell_type":"markdown","id":"01e4f95a-a59e-43d9-8363-56c3b9ea5e2f","metadata":{"tags":[],"id":"01e4f95a-a59e-43d9-8363-56c3b9ea5e2f"},"source":["## RNN Fundamentals\n","\n","RNNs fall in the category of neural networks that maintain some kind of **state**. They can process sequential data of arbitrary length. By doing so, they overcome certain limitations faced by classical neural networks. Classical NNs only accept fixed-length vectors as input and output fixed-length vectors. RNNs operate over sequences of vectors. Classical NNs aren't built to consider the sequential nature of some data. RNNs work with sequential data forms like language, video frames, time series, and so on.\n","\n","The RNN layer uses a for-loop to iterate over the time-steps of a sequence, and maintains an internal state that encodes information about all time-steps that have been observed so far. The Keras RNN API has built-in `keras.layers.RNN` and `keras.layers.LSTM` layers that make it easy to quickly build RNN models.\n"]},{"cell_type":"markdown","id":"f2d46976-6f1c-48ee-bbdd-ba3ee0ebc3c3","metadata":{"id":"f2d46976-6f1c-48ee-bbdd-ba3ee0ebc3c3"},"source":["### Vanilla Recurrent Neural Network\n","\n","RNNs use these two simple formulas:\n","\n","$$ \\mathbf s_t = \\mbox{tanh }(U \\mathbf x_t + W \\mathbf s_{t-1}) $$\n","\n","$$ \\mathbf y_t = V \\mathbf s_t $$ \n","\n","The following plot shows the hyperbolic tan function, `tanh`:\n","\n","<img src=\"https://github.com/DataScienceUB/DeepLearningMaster2019/blob/master/images/TanhReal.gif?raw=1\" alt=\"\" style=\"width: 300px;\">\n","\n","#### Terminology:\n","* $s_t$ current network, or the hidden state\n","* $\\mathbf s_{t-1}$ previous hidden state\n","* $\\mathbf x_t$ current input\n","* $U, V, W$ matrices that are parameters of the RNN\n","* $\\mathbf y_t$ output at time $t$\n","\n","These equations say that the current network state or the hidden state, is a function of the previous hidden state and the current input. \n","\n","### Unrolling in time of a RNN\n","\n","Given an input sequence, we apply RNN formulas in a recurrent way until we process all input elements. The $U,V,W$ parameters are shared across all recurrent steps. This implies that at each time step, the output is a function of all inputs from previous time steps. The network has a form of memory, encoding information about the time-steps it has seen so far.\n","\n","Some important observations:\n","- The initial values for $U,V,W$ as well as for $\\mathbf s$ must be provided when training an RNN.\n","- Hidden state  acts as a memory of the network. It can capture information about the previous steps. It embeds the representation of the sequence.\n","- We can look at the network's output at every stage or just the final stage.\n","\n","### Training an RNN\n","\n","A RNN has a layer for each time step, and its weights are shared across time. It is trained using backpropagation through time, and is done using the following steps:\n","- The input or the training set is made of several input ($n$-dimensional) sequences $\\{\\mathbf{X}_i \\}$ and corresponding outcomes. Each element of a sequence $\\mathbf{x}_j \\in \\mathbf{X}_i$ is also a vector.\n","- We use a loss function to measure how well the network's output fits to the expected outcome, such as ground truth.\n","- We apply an optimization method like stochastic gradient descent or Adam to optimize the loss function\n","- After the forward pass, gradients of the cost function are propagated backwards through the unrolled network"]},{"cell_type":"markdown","id":"ceaa5f19-ceea-43bd-876c-32e9a8909be1","metadata":{"id":"ceaa5f19-ceea-43bd-876c-32e9a8909be1"},"source":["## Types of RNNs\n","\n","Predicting the output, $y_t$, at each time step is not always the case. Different RNN architectures can be used to solve different kinds of problems.\n"]},{"cell_type":"markdown","id":"9869ab6e-db77-403b-8755-011eeb0e116e","metadata":{"id":"9869ab6e-db77-403b-8755-011eeb0e116e"},"source":["|Type|Input|Output|Example problem\n","|-|-|-|-\n","|*many-to-many*|An input sequence|An output sequence|Part of Speech (POS) tagging\n","|*many-to-one*|An input sequence|Value of output sequence for last timestep|Text classification: positive tweet or negative?\n","|*one-to-many*|Single value of input sequence|An output sequence| Given an input image, predict sequence data\n"]},{"cell_type":"markdown","id":"9e1fc57f-19f8-4076-aa2b-a13bb3f56675","metadata":{"id":"9e1fc57f-19f8-4076-aa2b-a13bb3f56675"},"source":["## Pre-trained RNNs\n"]},{"cell_type":"markdown","id":"7499aaba-6a3c-4933-96fc-881ba3c3d401","metadata":{"id":"7499aaba-6a3c-4933-96fc-881ba3c3d401"},"source":["In this section, we will be experimenting with existing RNNs. We will use the NLP disaster dataset. The dataset contains a `test.csv` and a `train.csv` each of which have the following information:\n","\n","* The text of a tweet\n","* A keyword from that tweet (although this may be blank!)\n","* The location the tweet was sent from (may also be blank)\n","\n","Our task is to predict whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n"]},{"cell_type":"markdown","id":"f2457c40-04ea-4d4f-acc8-527f947e428d","metadata":{"id":"f2457c40-04ea-4d4f-acc8-527f947e428d"},"source":["Let us start by downloading and unzipping the dataset.\n"]},{"cell_type":"code","execution_count":null,"id":"e7b8c05f-0165-4ceb-bdd1-9349525dd737","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210,"referenced_widgets":["b5972315c00846ff94c94d831cd0f7f5","8798c78ad9d54c73b298097d1c21ffa0","6db8015f8ac042abbe98bf9eb54c32d7","11e216e0f84843f6b10627baa10a75b1","353236e6e5f44dc5a63461c4bb3eb78b","01288c4399014d62b7035f0dbe325ab9","89b8cc32ee604d3b8ca0faf978f8e73e","201c3c984d184d838d9b0ca5da308da9","bd02c126789841bf9010bfab9ae44023","6b41ee1634114d1dac927ed7317a6875","c3b0eff2cc6a436c8483284be6e5ce3a","7a987a5468504d6b8ff84506fe2a61b4","7fb9404f86594457856330d7336e3d45","676f5ac4c36a4c2fb4e9b56935492c4d","9971c3933b284c0394b07f8d16d80a70","ad1d1385e0de4b279bb2859abb0e4cb3","30f5dce37c51400d9175bc3e7910b5f9","aebfae7a95b24e82bedfde50d646e61e","cf83ee5ff0a94e5ebb1db4841b8a4914","baef3b7af0964969930d355e4eaf2f09","4763dca5bd9a4220824b77fd41915690","866816948ad94df8b408fd14c5813723"]},"id":"e7b8c05f-0165-4ceb-bdd1-9349525dd737","executionInfo":{"status":"ok","timestamp":1685293911228,"user_tz":-330,"elapsed":5628,"user":{"displayName":"S NIKHIL RAO","userId":"17719059677933628828"}},"outputId":"90e12567-4e29-47c2-ffb5-4bc39e6ec40e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading nlp_disaster.zip:   0%|          | 0/607343 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5972315c00846ff94c94d831cd0f7f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a987a5468504d6b8ff84506fe2a61b4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saved to '.'\n"]}],"source":["await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module4/L1/nlp_disaster.zip\")"]},{"cell_type":"markdown","id":"53138509-46b3-417a-b861-c312e73bf0b6","metadata":{"id":"53138509-46b3-417a-b861-c312e73bf0b6"},"source":["Now we will read in the train dataset. Here we use `frac=1` so all rows in the training dataset are returned in a random order. We also set a random state to ensure reproducibility of results.\n"]},{"cell_type":"code","execution_count":null,"id":"f2642e5d-631b-494a-9cc3-ae8247104ea8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"f2642e5d-631b-494a-9cc3-ae8247104ea8","executionInfo":{"status":"ok","timestamp":1685293915207,"user_tz":-330,"elapsed":781,"user":{"displayName":"S NIKHIL RAO","userId":"17719059677933628828"}},"outputId":"1930830e-b88c-4288-c9e4-24536dae1a25"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id      keyword               location  \\\n","2644  3796  destruction                    NaN   \n","2227  3185       deluge                    NaN   \n","5448  7769       police                     UK   \n","132    191   aftershock                    NaN   \n","6845  9810       trauma  Montgomery County, MD   \n","\n","                                                   text  target  \n","2644  So you have a new weapon that can cause un-ima...       1  \n","2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n","5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n","132   Aftershock back to school kick off was great. ...       0  \n","6845  in response to trauma Children of Addicts deve...       0  "],"text/html":["\n","  <div id=\"df-1f34ef47-fd61-486c-8724-82da424ff782\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2644</th>\n","      <td>3796</td>\n","      <td>destruction</td>\n","      <td>NaN</td>\n","      <td>So you have a new weapon that can cause un-ima...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2227</th>\n","      <td>3185</td>\n","      <td>deluge</td>\n","      <td>NaN</td>\n","      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5448</th>\n","      <td>7769</td>\n","      <td>police</td>\n","      <td>UK</td>\n","      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>191</td>\n","      <td>aftershock</td>\n","      <td>NaN</td>\n","      <td>Aftershock back to school kick off was great. ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6845</th>\n","      <td>9810</td>\n","      <td>trauma</td>\n","      <td>Montgomery County, MD</td>\n","      <td>in response to trauma Children of Addicts deve...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f34ef47-fd61-486c-8724-82da424ff782')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1f34ef47-fd61-486c-8724-82da424ff782 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1f34ef47-fd61-486c-8724-82da424ff782');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["train_df = pd.read_csv(\"train.csv\")\n","# shuffle the dataset \n","train_df_shuffled = train_df.sample(frac=1, random_state=42)\n","train_df_shuffled.head()"]},{"cell_type":"markdown","id":"aa8cee2c-5ef4-482f-8c8e-dbaad8d026d9","metadata":{"id":"aa8cee2c-5ef4-482f-8c8e-dbaad8d026d9"},"source":["We will use 90% of the entire labelled dataset for training, and 10% of it for testing purposes.\n"]},{"cell_type":"code","execution_count":null,"id":"d1e0a9d5-554c-476f-ab54-cfeff7b352ed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1e0a9d5-554c-476f-ab54-cfeff7b352ed","executionInfo":{"status":"ok","timestamp":1685293951042,"user_tz":-330,"elapsed":668,"user":{"displayName":"S NIKHIL RAO","userId":"17719059677933628828"}},"outputId":"a0b15cda-4349-46d5-d53d-c9c667cb8a7c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((6851,), (6851,))"]},"metadata":{},"execution_count":7}],"source":["# split the data into 90% training and 10% testing\n","X_train, X_test, y_train, y_test = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n","                                                    train_df_shuffled[\"target\"].to_numpy(),\n","                                                    test_size = 0.1,\n","                                                    random_state=42)\n","X_train.shape, y_train.shape"]},{"cell_type":"code","execution_count":null,"id":"e72599f3-17fc-4e43-b2d2-be73c93595a4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e72599f3-17fc-4e43-b2d2-be73c93595a4","executionInfo":{"status":"ok","timestamp":1685293978995,"user_tz":-330,"elapsed":657,"user":{"displayName":"S NIKHIL RAO","userId":"17719059677933628828"}},"outputId":"33a2faae-4406-4e38-f490-49d10ab0fee9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['@mogacola @zamtriossu i screamed after hitting tweet',\n","       'Imagine getting flattened by Kurt Zouma',\n","       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n","       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n","       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n","      dtype=object)"]},"metadata":{},"execution_count":8}],"source":["X_train[0:5]"]},{"cell_type":"markdown","id":"7d9bed73-1fb5-4f47-b964-1b5a133eceea","metadata":{"id":"7d9bed73-1fb5-4f47-b964-1b5a133eceea"},"source":["`TextVectorization` is a preprocessing layer which maps text features to integer sequences. We also specify `lower_and_strip_punctuation` as the standardization method to apply to the input text. The text will be lowercased and all punctuation removed. Next we split on the whitespace, and pass `None` to `ngrams` so no ngrams are created.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"463f67bb-31fc-44d5-9f69-68f705e7b45c","metadata":{"id":"463f67bb-31fc-44d5-9f69-68f705e7b45c"},"outputs":[],"source":["text_vectorizer = TextVectorization(max_tokens=None, \n","                                    #remove punctuation and make letters lowercase\n","                                    standardize=\"lower_and_strip_punctuation\", \n","                                    #whitespace delimiter\n","                                    split=\"whitespace\", \n","                                    #dont group anything, every token alone\n","                                    ngrams = None, \n","                                    output_mode =\"int\",\n","                                    #length of each sentence == length of largest sentence\n","                                    output_sequence_length=None\n","                                    )"]},{"cell_type":"code","execution_count":null,"id":"44018c57-ff84-490c-9d5a-5cf3a229bb88","metadata":{"id":"44018c57-ff84-490c-9d5a-5cf3a229bb88"},"outputs":[],"source":["# define hyperparameters\n","\n","# number of words in the vocabulary \n","max_vocab_length = 10000\n","# tweet average length\n","max_length = 15"]},{"cell_type":"markdown","id":"169e1042-2608-4901-bc22-0d0f001216cd","metadata":{"id":"169e1042-2608-4901-bc22-0d0f001216cd"},"source":["Below we define an `Embedding` layer with a vocabulary of 10,000, a vector space of 128 dimensions in which words will be embedded, and input documents that have 15 words each.\n"]},{"cell_type":"code","execution_count":null,"id":"c280fb00-c208-4091-9fec-e1d70ae2eaae","metadata":{"id":"c280fb00-c208-4091-9fec-e1d70ae2eaae"},"outputs":[],"source":["embedding = layers.Embedding(input_dim= max_vocab_length,\n","                             output_dim=128,\n","                             input_length=max_length)"]},{"cell_type":"markdown","id":"3171967c-5beb-4af4-97d6-dbb09db34952","metadata":{"id":"3171967c-5beb-4af4-97d6-dbb09db34952"},"source":["The `hub.KerasLayer` wraps a SavedModel (or a legacy TF1 Hub format) as a Keras Layer. The `universal-sentence-encoder` is an encoder of greater-than-word length text trained on a variety of data. It can be used for text classification, semantic similarity, clustering, and other natural language tasks. \n","\n","> We can train a simple binary text classifier on top of any TF-Hub module that can embed sentences. The Universal Sentence Encoder was partially trained with custom text classification tasks in mind. These kinds of classifiers can be trained to perform a wide variety of classification tasks often with a very small amount of labeled examples.\n","\n","More on this is found in the Tensorflow Hub [documentation](https://tfhub.dev/google/universal-sentence-encoder/4?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera747-2022-01-01)\n"]},{"cell_type":"code","execution_count":null,"id":"35ada2b2-1351-4322-bb29-000d4cf892fa","metadata":{"id":"35ada2b2-1351-4322-bb29-000d4cf892fa"},"outputs":[],"source":["encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n","                               input_shape=[],\n","                               dtype = tf.string,\n","                               trainable=False,\n","                               name=\"pretrained\")"]},{"cell_type":"markdown","id":"45968087-0dc6-4b00-a346-f35a54cd063c","metadata":{"id":"45968087-0dc6-4b00-a346-f35a54cd063c"},"source":["The `encoder_layer` will take as input variable length English text and the output is a 512 dimensional vector.\n"]},{"cell_type":"markdown","id":"db7b4333-fa87-4db3-aa5d-b1f723a6aa2f","metadata":{"id":"db7b4333-fa87-4db3-aa5d-b1f723a6aa2f"},"source":["We will add a Dense layer with unit 1 to create a simple binary text classifier on top of any TF-Hub module. Next, we will compile and fit it using 20 epochs.\n"]},{"cell_type":"code","execution_count":null,"id":"6a63a7ea-feb9-4b7c-acef-abe94d8d8f6c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6a63a7ea-feb9-4b7c-acef-abe94d8d8f6c","executionInfo":{"status":"ok","timestamp":1685297570538,"user_tz":-330,"elapsed":85814,"user":{"displayName":"S NIKHIL RAO","userId":"17719059677933628828"}},"outputId":"61d6b5fd-c6a2-473e-cd7e-4dbc9eceebf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","215/215 [==============================] - 8s 20ms/step - loss: 0.6499 - accuracy: 0.7234 - val_loss: 0.6142 - val_accuracy: 0.7756\n","Epoch 2/20\n","215/215 [==============================] - 3s 12ms/step - loss: 0.5835 - accuracy: 0.7851 - val_loss: 0.5650 - val_accuracy: 0.7782\n","Epoch 3/20\n","215/215 [==============================] - 3s 12ms/step - loss: 0.5405 - accuracy: 0.7923 - val_loss: 0.5335 - val_accuracy: 0.7835\n","Epoch 4/20\n","215/215 [==============================] - 2s 12ms/step - loss: 0.5115 - accuracy: 0.7952 - val_loss: 0.5118 - val_accuracy: 0.7848\n","Epoch 5/20\n","215/215 [==============================] - 3s 14ms/step - loss: 0.4911 - accuracy: 0.8000 - val_loss: 0.4970 - val_accuracy: 0.7861\n","Epoch 6/20\n","215/215 [==============================] - 3s 15ms/step - loss: 0.4761 - accuracy: 0.8013 - val_loss: 0.4863 - val_accuracy: 0.7861\n","Epoch 7/20\n","215/215 [==============================] - 2s 11ms/step - loss: 0.4647 - accuracy: 0.8028 - val_loss: 0.4787 - val_accuracy: 0.7953\n","Epoch 8/20\n","215/215 [==============================] - 2s 11ms/step - loss: 0.4559 - accuracy: 0.8065 - val_loss: 0.4729 - val_accuracy: 0.7940\n","Epoch 9/20\n","215/215 [==============================] - 3s 12ms/step - loss: 0.4488 - accuracy: 0.8069 - val_loss: 0.4683 - val_accuracy: 0.7913\n","Epoch 10/20\n","215/215 [==============================] - 3s 16ms/step - loss: 0.4431 - accuracy: 0.8067 - val_loss: 0.4647 - val_accuracy: 0.7953\n","Epoch 11/20\n","215/215 [==============================] - 3s 13ms/step - loss: 0.4382 - accuracy: 0.8088 - val_loss: 0.4617 - val_accuracy: 0.7966\n","Epoch 12/20\n","215/215 [==============================] - 3s 12ms/step - loss: 0.4341 - accuracy: 0.8107 - val_loss: 0.4592 - val_accuracy: 0.7992\n","Epoch 13/20\n","215/215 [==============================] - 2s 11ms/step - loss: 0.4305 - accuracy: 0.8114 - val_loss: 0.4574 - val_accuracy: 0.7992\n","Epoch 14/20\n","215/215 [==============================] - 3s 12ms/step - loss: 0.4276 - accuracy: 0.8121 - val_loss: 0.4558 - val_accuracy: 0.7992\n","Epoch 15/20\n","215/215 [==============================] - 4s 18ms/step - loss: 0.4248 - accuracy: 0.8132 - val_loss: 0.4547 - val_accuracy: 0.8005\n","Epoch 16/20\n","215/215 [==============================] - 2s 11ms/step - loss: 0.4225 - accuracy: 0.8145 - val_loss: 0.4533 - val_accuracy: 0.8005\n","Epoch 17/20\n","215/215 [==============================] - 2s 11ms/step - loss: 0.4204 - accuracy: 0.8156 - val_loss: 0.4523 - val_accuracy: 0.8018\n","Epoch 18/20\n","215/215 [==============================] - 2s 12ms/step - loss: 0.4186 - accuracy: 0.8158 - val_loss: 0.4516 - val_accuracy: 0.8005\n","Epoch 19/20\n","215/215 [==============================] - 2s 11ms/step - loss: 0.4169 - accuracy: 0.8164 - val_loss: 0.4505 - val_accuracy: 0.8031\n","Epoch 20/20\n","215/215 [==============================] - 4s 17ms/step - loss: 0.4154 - accuracy: 0.8161 - val_loss: 0.4499 - val_accuracy: 0.8031\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5ca4432f80>"]},"metadata":{},"execution_count":14}],"source":["model = tf.keras.Sequential([\n","                             encoder_layer,\n","                             layers.Dense(1,activation=\"sigmoid\")], name=\"model_pretrained\")\n","model.compile(loss=\"binary_crossentropy\",\n","                     optimizer=\"adam\",\n","                     metrics=[\"accuracy\"])\n","\n","model.fit(x=X_train,\n","              y=y_train,\n","              epochs=20,\n","              validation_data=(X_test,y_test))"]},{"cell_type":"code","execution_count":null,"id":"d83f98ff-05fc-46ae-818f-80c04088f332","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d83f98ff-05fc-46ae-818f-80c04088f332","executionInfo":{"status":"ok","timestamp":1685297588651,"user_tz":-330,"elapsed":930,"user":{"displayName":"S NIKHIL RAO","userId":"17719059677933628828"}},"outputId":"9bede733-5f78-46b5-97e4-b0090eb5a8c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 10ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.8031496062992126,\n"," 'precision': 0.8035439751309367,\n"," 'recall': 0.8031496062992126,\n"," 'f1': 0.8022435150304292}"]},"metadata":{},"execution_count":15}],"source":["calculate_results(y_true=y_test,\n","                  y_pred=tf.squeeze(tf.round(model.predict(X_test))))"]},{"cell_type":"markdown","id":"e5e8045c-ad6e-423b-b55f-542b8fa6a2d5","metadata":{"id":"e5e8045c-ad6e-423b-b55f-542b8fa6a2d5"},"source":["The model is able to predict the tweet class with a fairly high accuracy.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""},"colab":{"provenance":[{"file_id":"1IXNu8zkyZmfhv-q6A4w8ZBaeSPS3nT4V","timestamp":1685297774968}]},"widgets":{"application/vnd.jupyter.widget-state+json":{"b5972315c00846ff94c94d831cd0f7f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8798c78ad9d54c73b298097d1c21ffa0","IPY_MODEL_6db8015f8ac042abbe98bf9eb54c32d7","IPY_MODEL_11e216e0f84843f6b10627baa10a75b1"],"layout":"IPY_MODEL_353236e6e5f44dc5a63461c4bb3eb78b"}},"8798c78ad9d54c73b298097d1c21ffa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01288c4399014d62b7035f0dbe325ab9","placeholder":"​","style":"IPY_MODEL_89b8cc32ee604d3b8ca0faf978f8e73e","value":"Downloading nlp_disaster.zip: 100%"}},"6db8015f8ac042abbe98bf9eb54c32d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_201c3c984d184d838d9b0ca5da308da9","max":607343,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd02c126789841bf9010bfab9ae44023","value":607343}},"11e216e0f84843f6b10627baa10a75b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b41ee1634114d1dac927ed7317a6875","placeholder":"​","style":"IPY_MODEL_c3b0eff2cc6a436c8483284be6e5ce3a","value":" 607343/607343 [00:03&lt;00:00, 376572.29it/s]"}},"353236e6e5f44dc5a63461c4bb3eb78b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01288c4399014d62b7035f0dbe325ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89b8cc32ee604d3b8ca0faf978f8e73e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"201c3c984d184d838d9b0ca5da308da9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd02c126789841bf9010bfab9ae44023":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b41ee1634114d1dac927ed7317a6875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3b0eff2cc6a436c8483284be6e5ce3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a987a5468504d6b8ff84506fe2a61b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7fb9404f86594457856330d7336e3d45","IPY_MODEL_676f5ac4c36a4c2fb4e9b56935492c4d","IPY_MODEL_9971c3933b284c0394b07f8d16d80a70"],"layout":"IPY_MODEL_ad1d1385e0de4b279bb2859abb0e4cb3"}},"7fb9404f86594457856330d7336e3d45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30f5dce37c51400d9175bc3e7910b5f9","placeholder":"​","style":"IPY_MODEL_aebfae7a95b24e82bedfde50d646e61e","value":"Extracting nlp_disaster.zip: 100%"}},"676f5ac4c36a4c2fb4e9b56935492c4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf83ee5ff0a94e5ebb1db4841b8a4914","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_baef3b7af0964969930d355e4eaf2f09","value":3}},"9971c3933b284c0394b07f8d16d80a70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4763dca5bd9a4220824b77fd41915690","placeholder":"​","style":"IPY_MODEL_866816948ad94df8b408fd14c5813723","value":" 3/3 [00:00&lt;00:00, 53.81it/s]"}},"ad1d1385e0de4b279bb2859abb0e4cb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30f5dce37c51400d9175bc3e7910b5f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aebfae7a95b24e82bedfde50d646e61e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf83ee5ff0a94e5ebb1db4841b8a4914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baef3b7af0964969930d355e4eaf2f09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4763dca5bd9a4220824b77fd41915690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"866816948ad94df8b408fd14c5813723":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}